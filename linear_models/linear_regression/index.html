
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Machine Learning Docs">
      
      
      
        <link rel="canonical" href="https://nickuzmenkov.github.io/ml_docs/linear_models/linear_regression/">
      
      
        <link rel="prev" href="../..">
      
      
        <link rel="next" href="../linear_classification/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.1.21">
    
    
      
        <title>Linear Regression - ML Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.eebd395e.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#linear-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ML Docs" class="md-header__button md-logo" aria-label="ML Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ML Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Linear Regression
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/nickuzmenkov/ml_docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ml_docs
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ML Docs" class="md-nav__button md-logo" aria-label="ML Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ML Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nickuzmenkov/ml_docs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ml_docs
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Linear Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Linear Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Linear Regression
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Linear Regression
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#closed-form-solution" class="md-nav__link">
    Closed-Form Solution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-descent" class="md-nav__link">
    Gradient Descent
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    Examples
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#closed-form-solution-with-numpy" class="md-nav__link">
    Closed-Form Solution with NumPy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#closed-form-solution-with-scikit-learn" class="md-nav__link">
    Closed-Form Solution with scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#different-types-of-gradient-descent" class="md-nav__link">
    Different Types of Gradient Descent
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-types-of-regression" class="md-nav__link">
    Other types of regression
  </a>
  
    <nav class="md-nav" aria-label="Other types of regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#polynomial-regression" class="md-nav__link">
    Polynomial Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spline-regression" class="md-nav__link">
    Spline Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generalized-linear-models" class="md-nav__link">
    Generalized Linear Models
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../linear_classification/" class="md-nav__link">
        Linear Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../regularization/" class="md-nav__link">
        Regularization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#closed-form-solution" class="md-nav__link">
    Closed-Form Solution
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-descent" class="md-nav__link">
    Gradient Descent
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    Examples
  </a>
  
    <nav class="md-nav" aria-label="Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#closed-form-solution-with-numpy" class="md-nav__link">
    Closed-Form Solution with NumPy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#closed-form-solution-with-scikit-learn" class="md-nav__link">
    Closed-Form Solution with scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#different-types-of-gradient-descent" class="md-nav__link">
    Different Types of Gradient Descent
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-types-of-regression" class="md-nav__link">
    Other types of regression
  </a>
  
    <nav class="md-nav" aria-label="Other types of regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#polynomial-regression" class="md-nav__link">
    Polynomial Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spline-regression" class="md-nav__link">
    Spline Regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generalized-linear-models" class="md-nav__link">
    Generalized Linear Models
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="linear-models">Linear Models</h1>
<h2 id="linear-regression">Linear Regression</h2>
<p>Linear Regression is defined by</p>
<p>$$
\hat{y} = \boldsymbol{\theta}^T \boldsymbol{x},
$$</p>
<p>where $\hat{y}$ represents the predicted value, $\boldsymbol{\theta}$ is a $(n, 1)$ vector of model weights, $\boldsymbol{x}$ is a $(n, 1)$ vector of features, and $n$ is the number of features.</p>
<p>The mean squared error $\text{MSE}(\boldsymbol{\theta})$ is commonly used as the cost function:</p>
<p>$$
\text{MSE}(\boldsymbol{\theta}) = \frac{1}{m} \sum_{i=1}^m{(\boldsymbol{\theta}^T \boldsymbol{x}_i - y_i)^2} = \frac{1}{m}||\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{y}||_2^2,
$$</p>
<p>where $m$ represents the number of training samples, $\boldsymbol{X}$ is an $(m, n)$ matrix containing the training samples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The $|| x ||_2$ notation represents the Euclidean (or L2) norm of the vector. Similarly, $|| x ||_2^2$ represents the squared Euclidean norm.</p>
</div>
<p>There are 2 main solution approaches:</p>
<ul>
<li><strong>Closed-form solution</strong>: This approach computes the optimal parameters directly.</li>
<li><strong>Gradient descent</strong> (GD): GD iteratively finds nearly optimal parameters by fitting either the entire training set or its batches.</li>
</ul>
<h3 id="closed-form-solution">Closed-Form Solution</h3>
<p>To minimize the cost function $\text{MSE}(\boldsymbol{\theta})$, we seek the point at which its gradient vanishes:</p>
<p>$$
\nabla_{\boldsymbol{\theta}}{\text{MSE}(\boldsymbol{\theta})}=0,
$$</p>
<p>$$
\frac{1}{m}\nabla_{\boldsymbol{\theta}} |\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{y}|_2^2=0.
$$</p>
<p>Considering that $|\boldsymbol{X}|_2^2=\boldsymbol{X}^T\boldsymbol{X}$, we have:</p>
<p>$$
\nabla_{\boldsymbol{\theta}}{(\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{y})^T(\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{y})}=0,
$$</p>
<p>$$
\nabla_{\boldsymbol{\theta}}{(\boldsymbol{\theta}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{\theta}^T\boldsymbol{X}^T\boldsymbol{y}-\boldsymbol{y}^T\boldsymbol{X}\boldsymbol{\theta}+\boldsymbol{y}^T\boldsymbol{y})}=0.
$$</p>
<p>Utilizing an unidentified scalar triple product property:</p>
<p>$$
\nabla_{\boldsymbol{\theta}}{(\boldsymbol{\theta}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\theta}-2\boldsymbol{\theta}^T\boldsymbol{X}^T\boldsymbol{y}+\boldsymbol{y}^T\boldsymbol{y})}=0.
$$</p>
<p>Applying the gradient:</p>
<p>$$
2\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{\theta}-2\boldsymbol{X}^T\boldsymbol{y}=0,
$$</p>
<p>$$
\boxed{\boldsymbol{\theta}=(\boldsymbol{X}^T\boldsymbol{X})^{-1}\boldsymbol{X}^T\boldsymbol{y}}.
$$</p>
<p>The resultant equation is recognized as the <strong>normal equation</strong>.</p>
<div class="admonition note annotate">
<p class="admonition-title">Computational complexity</p>
<p>Because of computational complexity and fitting the entire dataset in memory, closed-form solution can be unsuitable for large $m$ and $n$ (i.e. large number of instances and features, respectively).</p>
</div>
<h3 id="gradient-descent">Gradient Descent</h3>
<p><strong>Gradient descent</strong> is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems.</p>
<div class="admonition warning annotate">
<p class="admonition-title">Mind scaling</p>
<p>Features must be put onto the same scale for good convergence.</p>
</div>
<p>Gradient descent begins with random initialization of model parameters and tweaks the model’s parameter vector $\boldsymbol{\theta}$ opposite to the gradient of the cost function at each iteration</p>
<p>$$ \boldsymbol{\theta} \leftarrow \boldsymbol{\theta} - \eta \nabla_{\boldsymbol{\theta}}{\text{MSE}(\boldsymbol{\theta})} $$</p>
<p>where $\eta$ is the <em>learning rate</em>.</p>
<p>The gradient vector $\nabla_{\boldsymbol{\theta}}{\text{MSE}(\boldsymbol{\theta})}$ is given by</p>
<p>$$ \nabla_{\boldsymbol{\theta}}{\text{MSE}(\boldsymbol{\theta})}= \begin{pmatrix} \frac{\partial}{\partial \theta_0} \text{MSE}(\boldsymbol{\theta}) \ \vdots \ \frac{\partial}{\partial \theta_n} \text{MSE}(\boldsymbol{\theta}) \end{pmatrix} = \frac{2}{m}\boldsymbol{X}^T(\boldsymbol{X}\boldsymbol{\theta}-\boldsymbol{y}) $$</p>
<p>(it was derived <a href="https://www.notion.so/Regression-366aa3c9e2dc4d3f91dad0034473a215">here</a>). Thus, partial derivatives are given by</p>
<p>$$ \frac{\partial}{\partial \theta_j}\text{MSE}(\boldsymbol{\theta})=\frac{2}{m}\sum_{i=1}^m{\left(\boldsymbol{\theta}^T\boldsymbol{x}^{(i)}-y^{(i)}\right)x_j^{(i)}} $$</p>
<p>The iterations continue until the norm of the gradient becomes less than the specified <em>tolerance</em> value $\epsilon$</p>
<p>$$ |\nabla_{\boldsymbol{\theta}}{\text{MSE}(\boldsymbol{\theta})}|&lt;\epsilon $$</p>
<p>The cost function $\text{MSE}(\boldsymbol{\theta})$ is <em>convex</em>, meaning that gradient descent is guaranteed to find the global minimum within the specified tolerance.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It can be shown that for a convex function and constant learning rate batch gradient descent time is $O(1/\epsilon)$.</p>
</div>
<p>There’s 3 types of Gradient Descent:</p>
<ul>
<li><em>Batch gradient descent</em> (shown above): the entire training set is used to compute the gradient. Guaranteed to find optimal parameters for convex cost functions. Gets slow with large datasets and lots of features and does not support out-of-core computations.</li>
<li><em>Mini-batch gradient descent</em>: a single <em>batch</em> is used to compute the gradient. Scale well to huge datasets and supports out-of-core computations.</li>
<li><em>Stochastic gradient descent</em>: a single instance is used to compute the gradient. May require learning rate schedule for good convergence. Scale well to huge datasets and supports out-of-core computations.</li>
</ul>
<p>Complexity is $O(m\times n)$.</p>
<h2 id="examples">Examples</h2>
<h3 id="closed-form-solution-with-numpy">Closed-Form Solution with NumPy</h3>
<p>Linear regression of a single feature synthetic dataset with noise.</p>
<p>The input data is given by</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">+</span> <span class="n">noise</span>
</code></pre></div>

<p>Solution</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

<h3 id="closed-form-solution-with-scikit-learn">Closed-Form Solution with scikit-learn</h3>
<p>The problem statement is the same as Closed-Form Solution by Hand example.</p>
<p>Solution</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
</code></pre></div>

<h3 id="different-types-of-gradient-descent">Different Types of Gradient Descent</h3>
<p>Batch gradient descent is not available in scikit-learn. However, it’s easy to implement:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">-=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">grad</span>
</code></pre></div>

<p>Stochastic gradient descent is available directly:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
</code></pre></div>

<p>Mini-batch gradient descent is not available in scikit-learn.</p>
<h2 id="other-types-of-regression">Other types of regression</h2>
<h3 id="polynomial-regression">Polynomial Regression</h3>
<p>Linear models, such as <code>LinearRegression</code> (<code>LogisticRegression</code>), <code>SGDClassifier</code> (<code>SGDRegressor</code>) can be extended to higher powers of input features with <code>PolynomialFeatures</code> from <code>sklearn.preprocessing</code>. It returns all possible permutations of a given degree, e.g. $x_1^2,x_1x_2,x_2^2$ for <code>degree=2</code> and two features $x_1,x_2$.</p>
<h3 id="spline-regression">Spline Regression</h3>
<p><em>Spline regression</em> can produce even more sophisticated relations by using a series of polynomial segments joining at specified knots. It is available with <code>SplineTransformer</code> from <code>sklearn.preprocessing</code>. The resulting segments can then be fit into regression model of one’s choice (<a href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py">see more</a>).</p>
<h3 id="generalized-linear-models">Generalized Linear Models</h3>
<p>The process of specifying knots in splines can be automated using <em>generalized additive models</em> (<em>GAM</em>) regression. GAMs are available in <code>pyGAM</code> package (<a href="https://pygam.readthedocs.io/en/latest/notebooks/quick_start.html#Fit-a-Model">see more</a>).</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "content.code.copy", "content.code.annotate", "content.code.select"], "search": "../../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.220ee61c.min.js"></script>
      
        
          <script src="../../javascripts/katex.js"></script>
        
      
        
          <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
        
      
        
          <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
        
      
    
  </body>
</html>